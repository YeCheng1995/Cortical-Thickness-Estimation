{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from PIL import Image, ImageDraw\n",
    "from scipy.spatial import ConvexHull\n",
    "from skimage import measure\n",
    "import cv2\n",
    "import math\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choice one image number num\n",
    "def choice_image(image,num):\n",
    "    numpy = image.get_fdata()\n",
    "    numpy = numpy.T\n",
    "    numpy = numpy[:,num]\n",
    "    return numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binarization of an image according to its intensity\n",
    "def intensity_seg(ct_numpy, min, max):\n",
    "    clipped = ct_numpy.clip(min, max)\n",
    "\n",
    "    clipped[clipped != max] = 1\n",
    "    clipped[clipped == max] = 0\n",
    "    return measure.find_contours(clipped, 0.99) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Euclidean distance between points of Contour array\n",
    "def contour_distance(contour):\n",
    "\n",
    "    dx = contour[0, 1] - contour[-1, 1]\n",
    "    dy = contour[0, 0] - contour[-1, 0]\n",
    "    #Euclidean distance between the first coordinate point and the last coordinate point\n",
    "    return np.sqrt(np.power(dx, 2) + np.power(dy, 2))\n",
    "\n",
    "# Determine true or false according to contour closure\n",
    "def set_is_closed(contour):\n",
    "    if contour_distance(contour) < 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_brain(contours):\n",
    "    body_and_brain_contours = []\n",
    "    vol_contours = []\n",
    "\n",
    "    for contour in contours:\n",
    "        hull = ConvexHull(contour)\n",
    "\n",
    "        # Set pixel limit\n",
    "        if hull.volume > 2000 and set_is_closed(contour):\n",
    "            body_and_brain_contours.append(contour)\n",
    "            vol_contours.append(hull.volume)\n",
    "\n",
    "    # Discard body contour\n",
    "    if len(body_and_brain_contours) == 1:\n",
    "\n",
    "        return body_and_brain_contours\n",
    "    \n",
    "    elif len(body_and_brain_contours) > 1:\n",
    "        vol_contours, body_and_brain_contours = \\\n",
    "        (list(t) for t in zip(*sorted(zip(vol_contours, \n",
    "                                          body_and_brain_contours))))\n",
    "        # Excluding the body contour, leaving only the brain contour\n",
    "        body_and_brain_contours.pop(-1)\n",
    "        if len(body_and_brain_contours) != 1:\n",
    "             body_and_brain_contours.pop(0)\n",
    "        return body_and_brain_contours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Pretreatment(npslice, level, window):\n",
    "    max = level + window/2\n",
    "    min = level - window/2\n",
    "    npslice = npslice.clip(min,max)\n",
    "    plt.imshow(np.flip(npslice,axis=0), cmap=\"gray\", origin=\"lower\")\n",
    "    return npslice "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a binary mask with the same size as the image\n",
    "def create_mask_from_polygon(image, contours):\n",
    "    brain_mask = np.array(Image.new('L', image.shape, 0))\n",
    "    for contour in contours:\n",
    "        x = contour[:, 0]\n",
    "        y = contour[:, 1]\n",
    "        polygon_tuple = list(zip(x, y))\n",
    "        img = Image.new('L', image.shape, 0)\n",
    "        \n",
    "        ImageDraw.Draw(img).polygon(polygon_tuple, outline=0, fill=1)\n",
    "        mask = np.array(img)\n",
    "        brain_mask += mask\n",
    "\n",
    "    brain_mask[brain_mask > 1] = 1  \n",
    "\n",
    "    return brain_mask.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the brain area\n",
    "def create_cortical_mask(brain_mask, ct_numpy):\n",
    "    cortical = brain_mask * ct_numpy  \n",
    "    \n",
    "    cortical[cortical == 0] = -1000\n",
    "    cortical[cortical >= 80] = -1000\n",
    "    cortical[cortical < 40] = -1000\n",
    "    cortical[cortical >= 40] = 1000\n",
    "    #print(' cortical', len( brain_contours))\n",
    "    #-1000black +1000write\n",
    " \n",
    "    return cortical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAACy0lEQVR4nO3YMQoDMQwAwdOR/39Z+YBJF7zFTCk3ahaBZ3cfoOe9vQBwJk6IEidEiROixAlRn1+PM+MrF/5sd+c0dzkhSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghanb39g7AgcsJUeKEKHFClDghSpwQJU6I+gI34gvJPjrjHQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image = nib.load('./raw_t1_subject_02.nii.gz')\n",
    "\n",
    "def distance_coclor(cortical1):\n",
    "    cortical_x, cortical_y = np.nonzero(cortical1+1000)  # get whirt part\n",
    "    for (x,y) in zip(cortical_x, cortical_y):\n",
    "        if(x+5 <len(cortical1) and y+5 <len(cortical1) and x-5 >0 and y-5 >0):\n",
    "            if((cortical1[x+5,y] != -1000 or cortical1[x-5,y] != -1000)\n",
    "              and (cortical1[x,y+5] != -1000 or cortical1[x,y-5] != -1000)):\n",
    "                cortical1[x,y] = 1000\n",
    "            else:\n",
    "                cortical1[x,y] = -2000\n",
    "    return cortical1  \n",
    "\n",
    "for i in range (image.shape[2]):\n",
    "    image_brain_numpy = choice_image(image,i) \n",
    "    image_brain_numpy = Pretreatment(image_brain_numpy,40, 80)\n",
    "    contours = intensity_seg(image_brain_numpy , min=20, max=35) \n",
    "    brain_contours = find_brain(contours)\n",
    "    \n",
    "    \n",
    "    if(type(image_brain_numpy)!=type(None) and type( brain_contours)!=type(None)):\n",
    "        brain_mask = create_mask_from_polygon(image_brain_numpy, brain_contours)\n",
    "        cortical = create_cortical_mask(brain_mask, image_brain_numpy)\n",
    "        plt.imshow(np.flip(cortical,axis=0), cmap=\"gray\", origin=\"lower\")\n",
    "        plt.axis('off') \n",
    "        plt.xticks([])  \n",
    "        plt.yticks([]) \n",
    "        plt.savefig('./BW_down/cortical'+ str(i), bbox_inches = 'tight',pad_inches = 0)\n",
    " \n",
    "        #Method 1\n",
    "        cort = np.array(cortical)\n",
    "        dis_cortical = distance_coclor(cort)\n",
    "        x_x, y_y = np.nonzero(dis_cortical)\n",
    "        for (x,y) in zip(x_x, y_y):\n",
    "            if dis_cortical[x,y] != 1000:\n",
    "                dis_cortical[x,y] = -1000    \n",
    "        plt.clf()\n",
    "        plt.imshow(dis_cortical , 'flag_r', interpolation='none' )\n",
    "        plt.imshow(cortical, 'copper', interpolation='none', alpha=0.5 )\n",
    "        plt.axis('off') \n",
    "        plt.xticks([])  \n",
    "        plt.yticks([])  \n",
    "        plt.savefig('./MAP_down1/thickness'+ str(i),  bbox_inches = 'tight',pad_inches = 0)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlay_and_save (i, j):\n",
    "    plt.imshow(j,'flag' ,interpolation='none')\n",
    "    plt.imshow(i,'flag', interpolation='none', alpha=0.8)\n",
    "    plt.axis('off') \n",
    "    plt.xticks([])  \n",
    "    plt.yticks([])  \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Method 2\n",
    "for k in range (image.shape[2]):\n",
    "    exist = os.path.exists('./BW_down/cortical'+str(k)+'.png')\n",
    "    \n",
    "    if exist == True:\n",
    " \n",
    "        img = cv2.imread('./BW_down/cortical'+ str(k) +'.png',0)\n",
    "        img = cv2.fastNlMeansDenoising(img,None,10,7,21)\n",
    "        \n",
    "        cortical_thickness = cv2.distanceTransform(img, cv2.DIST_L1, cv2.DIST_MASK_3)\n",
    "        ret, img_fore = cv2.threshold(cortical_thickness, 0.5 * cortical_thickness .max(), 255, cv2.THRESH_BINARY)\n",
    "        cortical_thickness1 = cv2.convertScaleAbs(cortical_thickness )\n",
    "        cortical_thickness2 = cv2.normalize(cortical_thickness1, None, 255,0, cv2.NORM_MINMAX, cv2.CV_8UC1)\n",
    "        #heatmap\n",
    "        heat_cortical_thickness = cv2.applyColorMap(cortical_thickness2, cv2.COLORMAP_HOT)\n",
    "        heat_cortical_thickness = cv2.convertScaleAbs(heat_cortical_thickness, alpha=2, beta=0)\n",
    "        heat_cortical_thickness_fore = heat_cortical_thickness\n",
    "\n",
    "        cortical_thickness1 = cv2.convertScaleAbs(img_fore )\n",
    "        cortical_thickness2 = cv2.normalize(cortical_thickness1, None, 255,0, cv2.NORM_MINMAX, cv2.CV_8UC1)\n",
    "        heat_cortical_thickness_fore = cv2.applyColorMap(cortical_thickness2, cv2.COLORMAP_OCEAN)\n",
    "        #dyeing\n",
    "        rows,cols,channels = heat_cortical_thickness_fore.shape\n",
    "        for i in range(rows):\n",
    "            for j in range(cols):\n",
    "                for n in range(channels):\n",
    "                    if n ==0:    \n",
    "                        if heat_cortical_thickness_fore[i][j][n]==255:\n",
    "                            heat_cortical_thickness_fore[i][j][n]=0\n",
    "\n",
    "\n",
    "        finaly_image = overlay_and_save(heat_cortical_thickness,heat_cortical_thickness_fore)\n",
    "        plt.axis('off') \n",
    "        plt.xticks([])  \n",
    "        plt.yticks([]) \n",
    "        plt.savefig('./MAP_down2/thickness'+ str(k), bbox_inches = 'tight',pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
